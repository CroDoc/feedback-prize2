max_length: 1024
stride: 512
mask: 0.2
skip_validation: 0
callbacks:
  patience: 20
  weights: true
epoch: 3
model:
  dropout: 0.2
  pretrained: true
  model_name: microsoft/deberta-large
optimizer:
  name: optim.AdamW
  weight_decay: 0.01
  head_lr_factor: 5.0
  params:
    lr: 3.0e-06
    eps: 1.0e-06
    betas: [0.9, 0.999]
scheduler:
  name: poly
  params:
    epochs: 7
    lr_end: 3.0e-07
    power: 3.0
  interval: step
  warmup: 0.2
train_loader:
  batch_size: 2
  drop_last: true
  num_workers: 16
  pin_memory: false
  shuffle: true
val_loader:
  batch_size: 16
  drop_last: false
  num_workers: 16
  pin_memory: false
  shuffle: false
trainer:
  accumulate_grad_batches: 1
  fast_dev_run: false
  num_sanity_val_steps: 0
  precision: 16
  resume_from_checkpoint: null
  val_check_interval: 0.1
